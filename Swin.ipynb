{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0efd2073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchaudio in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torch==2.7.1 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torchaudio) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch==2.7.1->torchaudio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch==2.7.1->torchaudio) (4.13.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch==2.7.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch==2.7.1->torchaudio) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch==2.7.1->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch==2.7.1->torchaudio) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch==2.7.1->torchaudio) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e12e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d974d342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from networks.vision_transformer import SwinUnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90b72f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x192d8d136d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config:\n",
    "    root_path = \"./Dataset\"  # <-- This must exist!\n",
    "    img_size = 224\n",
    "    num_classes = 3\n",
    "    base_lr = 0.01\n",
    "    batch_size = 4\n",
    "    max_epochs = 100\n",
    "    n_gpu = 1\n",
    "    num_workers = 4\n",
    "    eval_interval = 5\n",
    "    seed = 42\n",
    "    snapshot_path = \"./swin_output\"\n",
    "    pretrained_ckpt = \"./pretrained_ckpt/swin_tiny_patch4_window7_224.pth\"\n",
    "\n",
    "args = Config()\n",
    "\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(args.snapshot_path, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(args.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bc4deb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class HepaticDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(image_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.image_files[idx])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return {\n",
    "            'image': image.float(),\n",
    "            'label': mask.long().squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab07f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((args.img_size, args.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = HepaticDataset(\n",
    "    image_dir=os.path.join(args.root_path, '2D_Sliced_Images'),\n",
    "    mask_dir=os.path.join(args.root_path, '2D_Sliced_Masks'),\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e84bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, input, target, smooth=1e-5, softmax=True):\n",
    "        if softmax:\n",
    "            input = torch.softmax(input, dim=1)\n",
    "\n",
    "        target_onehot = torch.eye(self.num_classes)[target].permute(0, 3, 1, 2).to(input.device)\n",
    "\n",
    "        dims = (0, 2, 3)\n",
    "        intersection = torch.sum(input * target_onehot, dims)\n",
    "        cardinality = torch.sum(input + target_onehot, dims)\n",
    "\n",
    "        dice = (2. * intersection + smooth) / (cardinality + smooth)\n",
    "        return 1. - dice.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778ec08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from yacs) (6.0.2)\n",
      "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: yacs\n",
      "Successfully installed yacs-0.1.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install yacs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143869df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yacs.config import CfgNode as CN\n",
    "import yaml\n",
    "\n",
    "# Load YAML into a dictionary\n",
    "with open('configs/swin_tiny_patch4_window7_224_lite.yaml', 'r') as f:\n",
    "    yaml_cfg = yaml.safe_load(f)\n",
    "\n",
    "# Convert dictionary to CfgNode (nested access support)\n",
    "config = CN(yaml_cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f64d7d6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvidia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnvidia\u001b[49m\u001b[38;5;241m-\u001b[39msmi\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nvidia' is not defined"
     ]
    }
   ],
   "source": [
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "315c772f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "547a4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA available:\u001b[39m\u001b[38;5;124m\"\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDevice Name:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_device_name\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\cuda\\__init__.py:544\u001b[0m, in \u001b[0;36mget_device_name\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_name\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    533\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the name of a device.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \n\u001b[0;32m    535\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m        str: the name of the device\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_device_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mname\n",
      "File \u001b[1;32mc:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\cuda\\__init__.py:576\u001b[0m, in \u001b[0;36mget_device_properties\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_device_properties\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _CudaDeviceProperties:\n\u001b[0;32m    565\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Get the properties of a device.\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \n\u001b[0;32m    567\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m        _CudaDeviceProperties: the properties of the device\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# will define _get_device_properties\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     device \u001b[38;5;241m=\u001b[39m _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count():\n",
      "File \u001b[1;32mc:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\cuda\\__init__.py:363\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3970dcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6aaf14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.7.1\n",
      "Uninstalling torch-2.7.1:\n",
      "  Successfully uninstalled torch-2.7.1\n",
      "Found existing installation: torchvision 0.22.1\n",
      "Uninstalling torchvision-0.22.1:\n",
      "  Successfully uninstalled torchvision-0.22.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tasni\\miniconda3\\envs\\tf\\Lib\\site-packages\\~orch'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\tasni\\miniconda3\\envs\\tf\\Lib\\site-packages\\~orchvision'.\n",
      "You can safely remove it manually.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall torch torchvision torchaudio -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f3ddff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files removed: 1118 (3445.1 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip cache purge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "045bbfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (27 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp39-cp39-win_amd64.whl (2817.1 MB)\n",
      "   ---------------------------------------- 0.0/2.8 GB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.8 GB 10.1 MB/s eta 0:04:40\n",
      "   ---------------------------------------- 0.0/2.8 GB 11.4 MB/s eta 0:04:07\n",
      "   ---------------------------------------- 0.0/2.8 GB 11.5 MB/s eta 0:04:05\n",
      "   ---------------------------------------- 0.0/2.8 GB 11.9 MB/s eta 0:03:57\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.2 MB/s eta 0:03:51\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.5 MB/s eta 0:03:44\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.7 MB/s eta 0:03:40\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.7 MB/s eta 0:03:41\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.8 MB/s eta 0:03:39\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.8 MB/s eta 0:03:38\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.9 MB/s eta 0:03:37\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.9 MB/s eta 0:03:37\n",
      "   ---------------------------------------- 0.0/2.8 GB 12.9 MB/s eta 0:03:37\n",
      "    --------------------------------------- 0.0/2.8 GB 12.8 MB/s eta 0:03:38\n",
      "    --------------------------------------- 0.0/2.8 GB 12.8 MB/s eta 0:03:38\n",
      "    --------------------------------------- 0.0/2.8 GB 12.8 MB/s eta 0:03:37\n",
      "    --------------------------------------- 0.0/2.8 GB 12.9 MB/s eta 0:03:36\n",
      "    --------------------------------------- 0.0/2.8 GB 12.9 MB/s eta 0:03:35\n",
      "    --------------------------------------- 0.1/2.8 GB 12.9 MB/s eta 0:03:35\n",
      "    --------------------------------------- 0.1/2.8 GB 12.9 MB/s eta 0:03:35\n",
      "    --------------------------------------- 0.1/2.8 GB 12.9 MB/s eta 0:03:35\n",
      "    --------------------------------------- 0.1/2.8 GB 12.8 MB/s eta 0:03:36\n",
      "    --------------------------------------- 0.1/2.8 GB 12.3 MB/s eta 0:03:45\n",
      "    --------------------------------------- 0.1/2.8 GB 12.3 MB/s eta 0:03:45\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 11.2 MB/s eta 0:04:08\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 5.0 MB/s eta 0:09:12\n",
      "    --------------------------------------- 0.1/2.8 GB 961.7 kB/s eta 0:47:49\n",
      "    --------------------------------------- 0.1/2.8 GB 953.0 kB/s eta 0:48:13\n",
      "    --------------------------------------- 0.1/2.8 GB 952.9 kB/s eta 0:48:11\n",
      "    --------------------------------------- 0.1/2.8 GB 961.2 kB/s eta 0:47:43\n",
      "    --------------------------------------- 0.1/2.8 GB 961.2 kB/s eta 0:47:43\n",
      "    --------------------------------------- 0.1/2.8 GB 961.2 kB/s eta 0:47:43\n",
      "    --------------------------------------- 0.1/2.8 GB 961.2 kB/s eta 0:47:43\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 611.7 kB/s eta 1:14:59\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n",
      "    --------------------------------------- 0.1/2.8 GB 315.9 kB/s eta 2:25:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in _fp_read\n",
      "    data = self._fp.read(chunk_amt)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 98, in read\n",
      "    data: bytes = self.__fp.read(amt)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\http\\client.py\", line 463, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\http\\client.py\", line 507, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\ssl.py\", line 1275, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\ssl.py\", line 1133, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 106, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 97, in _inner_run\n",
      "    return self.run(options, args)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 386, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 179, in resolve\n",
      "    self.factory.preparer.prepare_linked_requirements_more(reqs)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 554, in prepare_linked_requirements_more\n",
      "    self._complete_partial_requirements(\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 469, in _complete_partial_requirements\n",
      "    for link, (filepath, _) in batch_download:\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 184, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 55, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 65, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 587, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"C:\\Users\\tasni\\miniconda3\\envs\\tf\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='download.pytorch.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e03cfeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvcc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnvcc\u001b[49m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m-\u001b[39mversion\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nvcc' is not defined"
     ]
    }
   ],
   "source": [
    "nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6381c67b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvidia' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnvidia\u001b[49m\u001b[38;5;241m-\u001b[39msmi\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nvidia' is not defined"
     ]
    }
   ],
   "source": [
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27da05fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA Version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mcuda)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e75234",
   "metadata": {},
   "source": [
    "from yacs.config import CfgNode as CN\n",
    "import torch\n",
    "import os\n",
    "from networks.vision_transformer import SwinUnet\n",
    "\n",
    "# ---- Load YAML config ----\n",
    "from yaml import safe_load\n",
    "\n",
    "with open('configs/swin_tiny_patch4_window7_224_lite.yaml', 'r') as f:\n",
    "    yaml_cfg = safe_load(f)\n",
    "\n",
    "config = CN(yaml_cfg)\n",
    "\n",
    "# ---- Set extra training args ----\n",
    "class Args:\n",
    "    root_path = \"./Dataset\"\n",
    "    img_size = config.DATA.IMG_SIZE\n",
    "    num_classes = 3\n",
    "    base_lr = 0.01\n",
    "    batch_size = 4\n",
    "    max_epochs = 100\n",
    "    n_gpu = 1\n",
    "    num_workers = 4\n",
    "    eval_interval = 5\n",
    "    seed = 42\n",
    "    snapshot_path = \"./swin_output\"\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# ---- Ensure output folder exists ----\n",
    "os.makedirs(args.snapshot_path, exist_ok=True)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# ---- Step 1: Create the model ----\n",
    "model = SwinUnet(\n",
    "    config=config,\n",
    "    img_size=args.img_size,\n",
    "    num_classes=args.num_classes,\n",
    "    zero_head=True\n",
    ")\n",
    "\n",
    "# ---- Step 2: Load pretrained weights from config path ----\n",
    "model.load_from(config)\n",
    "\n",
    "# ---- Step 3: Wrap in DataParallel if multiple GPUs ----\n",
    "if args.n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# ---- Step 4: Move to GPU ----\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13616b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
      "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Installing collected packages: addict\n",
      "Successfully installed addict-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install addict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8495ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from addict import Dict\n",
    "\n",
    "# Load YAML file\n",
    "with open('configs/swin_tiny_patch4_window7_224_lite.yaml', 'r') as f:\n",
    "    config_dict = yaml.safe_load(f)\n",
    "\n",
    "# Convert to dot-accessible format\n",
    "config = Dict(config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a92e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "print(args.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf37d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_2tuple(x):\n",
    "    return x if isinstance(x, tuple) else (x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c526e",
   "metadata": {},
   "outputs": [],
   "source": [
    " tupImagesize=to_2tuple(args.img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f32275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformerSys expand initial----depths:[2, 2, 2, 2];depths_decoder:[1, 2, 2, 2];drop_path_rate:0.2;num_classes:3\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSwinUnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtupImagesize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mzero_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load pretrained checkpoint\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# model.load_from(config)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Use DataParallel if multiple GPUs\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32md:\\SwinUnet\\networks\\vision_transformer.py:30\u001b[0m, in \u001b[0;36mSwinUnet.__init__\u001b[1;34m(self, config, img_size, num_classes, zero_head, vis)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_head \u001b[38;5;241m=\u001b[39m zero_head\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswin_unet \u001b[38;5;241m=\u001b[39m \u001b[43mSwinTransformerSys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m                        \u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIN_CHANS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m                        \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEMBED_DIM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdepths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEPTHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNUM_HEADS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWINDOW_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMLP_RATIO\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQKV_BIAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mqk_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQK_SCALE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdrop_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDROP_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdrop_path_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDROP_PATH_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpatch_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMODEL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSWIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPATCH_NORM\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUSE_CHECKPOINT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\SwinUnet\\networks\\swin_transformer_unet_skip_expand_decoder_sys.py:632\u001b[0m, in \u001b[0;36mSwinTransformerSys.__init__\u001b[1;34m(self, img_size, patch_size, in_chans, num_classes, embed_dim, depths, depths_decoder, num_heads, window_size, mlp_ratio, qkv_bias, qk_scale, drop_rate, attn_drop_rate, drop_path_rate, norm_layer, ape, patch_norm, use_checkpoint, final_upsample, **kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_upsample \u001b[38;5;241m=\u001b[39m final_upsample\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# split image into non-overlapping patches\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed \u001b[38;5;241m=\u001b[39m \u001b[43mPatchEmbed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_chans\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_chans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_norm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m num_patches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed\u001b[38;5;241m.\u001b[39mnum_patches\n\u001b[0;32m    636\u001b[0m patches_resolution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed\u001b[38;5;241m.\u001b[39mpatches_resolution\n",
      "File \u001b[1;32md:\\SwinUnet\\networks\\swin_transformer_unet_skip_expand_decoder_sys.py:549\u001b[0m, in \u001b[0;36mPatchEmbed.__init__\u001b[1;34m(self, img_size, patch_size, in_chans, embed_dim, norm_layer)\u001b[0m\n\u001b[0;32m    547\u001b[0m img_size \u001b[38;5;241m=\u001b[39m to_2tuple(img_size)\n\u001b[0;32m    548\u001b[0m patch_size \u001b[38;5;241m=\u001b[39m to_2tuple(patch_size)\n\u001b[1;32m--> 549\u001b[0m patches_resolution \u001b[38;5;241m=\u001b[39m [\u001b[43mimg_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m patch_size[\u001b[38;5;241m0\u001b[39m], img_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m patch_size[\u001b[38;5;241m1\u001b[39m]]\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size \u001b[38;5;241m=\u001b[39m img_size\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size \u001b[38;5;241m=\u001b[39m patch_size\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = SwinUnet(config=config,\n",
    "                 img_size=tupImagesize,\n",
    "                 num_classes=args.num_classes,\n",
    "                 zero_head=True)\n",
    "\n",
    "# Load pretrained checkpoint\n",
    "# model.load_from(config)\n",
    "\n",
    "# Use DataParallel if multiple GPUs\n",
    "if args.n_gpu > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# Move to GPU\n",
    "model = model.cuda()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
